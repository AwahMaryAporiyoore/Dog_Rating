{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "072c3b1f",
   "metadata": {},
   "source": [
    "## WRANGLING EFFORTS\n",
    "\n",
    "The first stage for this project involved gathering data. The First Dataset, which is the Twitter Archive Enhanced dataset was provided in a csv format therefore did not require and extra data gathering tools to get the complete dataset.\n",
    "\n",
    "\n",
    "The Next Dataset was gathered using the request.get method. The data was gathered in a tsv format and with the help of the pandas dataframe, the tsv file was read in a csv format.\n",
    "\n",
    "\n",
    "The Third Dataset required using Twitterâ€™s API to gather the tweets information into a text file and them turning it into a pandas DataFrame.\n",
    "\n",
    "\n",
    "After successfully gathering all three dataset, a visual and programmatic assessments was undertaken to identify the quality and tidiness issues within the datasets. After the assessments, the following issues were deduced:\n",
    "\n",
    "1. The Twitter Archive and Tweets_DF datasets contains several NaN Values.\n",
    "\n",
    "2. The Twitter Archive Dataset contains individual columns for each dog stage.\n",
    "\n",
    "3. The Column names in the image prediction dataset is not descriptive hence confusing to understand what they stand for.\n",
    "\n",
    "4. There are constants within the dog naming.\n",
    "\n",
    "5. Certain columns within the datasets are not necessary to the analysis of the dataset.\n",
    "\n",
    "6. Inconsistent naming in the twitter archive dataset.\n",
    "\n",
    "7. Twitter Archive and Tweet_DF seem to contain the same information (Text, Source etc.)\n",
    "\n",
    "8. Is it necessary to have a p1, p2 and p3 dog names? There seem to be a repetition of the dog names.\n",
    "\n",
    "9. The image prediction dataset contains information of other objects which are not dogs.\n",
    "\n",
    "10. The id and id_str in the tweets_df dataset contains the same data.\n",
    "\n",
    "\n",
    "Using these issues, the next step was to clean the data. Functions like the drop, rename, merge etc was used to successfully clean the dataset.\n",
    "\n",
    "\n",
    "Finally, two main datasets (csvs) were created: twitter_archive_master2.csv (this dataset contains the Dog Ratings and twitter_archive_master1.csv (This dataset contains the Tweet_Predictions)\n",
    "\n",
    "\n",
    "Based on thse 2 newly created csvs, insights was derived and a visualization was produced.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2830950",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
